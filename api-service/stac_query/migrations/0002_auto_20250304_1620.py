# Generated by Django 5.1.6 on 2025-03-04 10:50
from django.db import migrations
from faker import Faker
import random
from datetime import datetime, timedelta

def populate_stac_data(apps, schema_editor):
    # Get the historical model (to handle migrations safely)
    stac = apps.get_model('stac_query', 'stac')

    # Initialize Faker for generating fake data
    fake = Faker()

    # Number of records to generate
    num_records = 100

    # Define choices for categorical fields
    beam_modes = ["IW", "SM", "EW", "WV"]
    flight_directions = ["ASCENDING", "DESCENDING"]
    granule_types = ["SLC", "GRD", "RAW", "OCN", "ETA"]
    platforms = ["SENTINEL-1A", "SENTINEL-1B", "SENTINEL-1C"]
    polarizations = ["VV", "HH", "VH", "HV"]
    processing_levels = ["Level-0", "Level-1", "Level-2"]
    sensors = ["C-SAR", "L-SAR"]

    # List to store records
    records = []

    for _ in range(num_records):
        # Generate timestamps
        start_time = fake.date_time_between(start_date="-2y", end_date="now")
        stop_time = start_time + timedelta(minutes=random.randint(1, 120))  # Up to 2 hours duration

        # Generate coordinates for center point
        center_lat = fake.latitude()
        center_lon = fake.longitude()

        # Generate a simple polygon in WKT format without using GEOS
        # Create a small polygon around the center point (rectangle with 5 points to close the loop)
        lat_offset = 0.1  # Small offset for polygon vertices
        lon_offset = 0.1
        coords = [
            (float(center_lon) - lon_offset, float(center_lat) - lat_offset),  # Bottom-left
            (float(center_lon) + lon_offset, float(center_lat) - lat_offset),  # Bottom-right
            (float(center_lon) + lon_offset, float(center_lat) + lat_offset),  # Top-right
            (float(center_lon) - lon_offset, float(center_lat) + lat_offset),  # Top-left
            (float(center_lon) - lon_offset, float(center_lat) - lat_offset),  # Close the polygon
        ]
        # Format coordinates as WKT POLYGON string
        coord_str = ", ".join([f"{lon} {lat}" for lon, lat in coords])
        wkt_polygon = f"POLYGON(({coord_str}))"

        # Generate fake S3 URLs (1-3 URLs as a comma-separated string)
        num_urls = random.randint(1, 3)
        s3_urls = ", ".join([f"s3://{fake.word()}/{fake.file_name(category='image')}" for _ in range(num_urls)])

        # Create a dictionary for the stac record
        record = {
            "type": "Feature",
            "geometry_type": "Polygon",
            "geometry_coordinates": wkt_polygon,  # WKT string, e.g., "POLYGON((-122.445678 37.887654, ...))"
            "beam_mode": random.choice(beam_modes),
            "browse": fake.url(),
            "bytes": random.randint(1000000, 1000000000),  # 1MB to 1GB
            "center_lat": center_lat,
            "center_lon": center_lon,
            "file_id": fake.uuid4()[:8].upper(),  # e.g., "FILE1234"
            "file_name": f"S1{random.choice(['A', 'B'])}_IW_SLC__1SDV_{start_time.strftime('%Y%m%dT%H%M%S')}.tif"[:100],  # Truncate to max_length=100
            "flight_direction": random.choice(flight_directions),
            "frame_number": random.randint(100, 999),
            "granuleType": random.choice(granule_types),
            "group_id": f"GROUP{random.randint(100, 999)}",
            "md5_sum": fake.md5()[:32],  # Ensure 32 characters
            "orbit": random.randint(10000, 99999),
            "path_number": random.randint(1, 175),
            "pge_version": f"{random.randint(1, 3)}.{random.randint(0, 9)}",
            "platform": random.choice(platforms),
            "polarization": random.choice(polarizations),
            "processing_date": fake.date_between(start_date="-2y", end_date="now"),
            "processing_level": random.choice(processing_levels),
            "s3_urls": s3_urls,
            "scene_name": f"S1{random.choice(['A', 'B'])}_IW_SLC__1SDV_{start_time.strftime('%Y%m%dT%H%M%S')}",
            "sensor": random.choice(sensors),
            "start_time": start_time,
            "stop_time": stop_time,
            "url": fake.url()
        }

        records.append(record)

    # Save the records to the database
    for record in records:
        stac_item = stac(**record)
        stac_item.save()

class Migration(migrations.Migration):
    dependencies = [
        ('stac_query', '0001_initial'),  # Adjust to match the previous migration
    ]

    operations = [
        migrations.RunPython(populate_stac_data),
    ]

